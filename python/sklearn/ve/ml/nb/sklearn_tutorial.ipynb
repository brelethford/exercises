{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scikit Learn Tutorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tables\n",
    "import sklearn as sk\n",
    "from sklearn import tree, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig test data:     134 cols, 710948 rows\n",
      "sig training data: 134 cols, 710948 rows\n",
      "bg test data:      123 cols, 3884472 rows\n",
      "bg training data:  123 cols, 3884472 rows\n"
     ]
    }
   ],
   "source": [
    "#import necessary data\n",
    "datafolder = '/home/relethford/git/practice/python/sklearn/ve/ml/data/nu_anis/2013/'\n",
    "sig_test = tables.open_file(datafolder+'test_sig.ds.hdf5')\n",
    "sig_train = tables.open_file(datafolder+'train_sig.ds.hdf5')\n",
    "bg_test = tables.open_file(datafolder+'test_data.ds.hdf5')\n",
    "bg_train = tables.open_file(datafolder+'train_data.ds.hdf5')\n",
    "#print shape of each set\n",
    "print('sig test data:     {} cols, {} rows'.format(len(sig_test.root.table.colnames),len(sig_test.root.table.cols.zen)))\n",
    "print('sig training data: {} cols, {} rows'.format(len(sig_train.root.table.colnames),len(sig_train.root.table.cols.zen)))\n",
    "print('bg test data:      {} cols, {} rows'.format(len(bg_test.root.table.colnames),len(bg_test.root.table.cols.zen)))\n",
    "print('bg training data:  {} cols, {} rows'.format(len(bg_train.root.table.colnames),len(bg_train.root.table.cols.zen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's set up a fcn that grabs a given variable from a given dataset, but only out to N events.\n",
    "N = 10000\n",
    "def getValue(colName, datafile):\n",
    "  value = datafile.get_node('/','table').col(colName)[0:N]\n",
    "  return np.array(list(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make an array for each of the for data sets, each having the variables we want to investigate.\n",
    "def varStack(tuple_vars):\n",
    "    return np.vstack(tuple_vars).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For now, we'll take two variables. Lizz says these two (bayes_rat, cog_z) have greatest separation power.\n",
    "#Add a target for each point - for bg, 0, for sig, 1.\n",
    "s_test  = varStack((getValue('bayes_rat', sig_test),getValue('cog_z', sig_test),np.ones(N)))\n",
    "s_train = varStack((getValue('bayes_rat', sig_train),getValue('cog_z', sig_train),np.ones(N)))\n",
    "b_test   = varStack((getValue('bayes_rat', bg_test),getValue('cog_z', bg_test),np.zeros(N)))\n",
    "b_train  = varStack((getValue('bayes_rat', bg_train),getValue('cog_z', bg_train),np.zeros(N)))\n",
    "#Note - THIS is the part where the code stalls like crazy. Either need to figure out how to only access SOME of the data...\n",
    "#...or else chop it up ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  20.08934919  105.95520231    1.        ]\n",
      " [  25.3983473    65.84812408    1.        ]\n",
      " [  64.54650211 -327.96772998    1.        ]\n",
      " ..., \n",
      " [  72.7680737   172.40375962    1.        ]\n",
      " [  18.32085279  213.24193715    1.        ]\n",
      " [  74.08932732  -86.56194218    1.        ]]\n",
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(s_test)\n",
    "print(np.shape(s_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine the test and train arrays.\n",
    "test = np.concatenate((s_test,b_test))\n",
    "train = np.concatenate((s_train,b_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier. This is what is suggested in the tutorial for a simple vector classifier.\n",
    "classifier = svm.SVC(gamma=0.001, probability=True)\n",
    "#Based on what I know about machine learning, gamma is a learning speed parameter for minimization. The higher it is, the faster the fit converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sklearn takes over from here to fit these features in order to predict which digit they are. We divide into a teaching and target sample.\n",
    "classifier.fit(train[:,0:2],train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we can use that fit to classify the expected target for the remaining handwriting samples.\n",
    "expected = test[:,-1]\n",
    "predicted = classifier.predict(test[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 0.  1.  1.  1.  1.  1.  1.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#It doesn't line up perfectly... but let's see how well it predicts over 10,000.\n",
    "print(expected[0:10])\n",
    "print(predicted[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.91      0.87     10000\n",
      "        1.0       0.90      0.82      0.85     10000\n",
      "\n",
      "avg / total       0.86      0.86      0.86     20000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[9078  922]\n",
      " [1847 8153]]\n"
     ]
    }
   ],
   "source": [
    "#Finally, let's measure how well this predicter works.\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = classifier.predict_proba(test[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72379894,  0.27620106],\n",
       "       [ 0.07182212,  0.92817788],\n",
       "       [ 0.01738015,  0.98261985],\n",
       "       [ 0.32871037,  0.67128963],\n",
       "       [ 0.21518477,  0.78481523],\n",
       "       [ 0.1149441 ,  0.8850559 ],\n",
       "       [ 0.06188867,  0.93811133],\n",
       "       [ 0.69346043,  0.30653957],\n",
       "       [ 0.0080759 ,  0.9919241 ],\n",
       "       [ 0.00671487,  0.99328513]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
