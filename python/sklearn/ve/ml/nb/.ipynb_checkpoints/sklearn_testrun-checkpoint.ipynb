{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tables\n",
    "import sklearn as sk\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the online materials for sklearn:\n",
    "from sklearn import datasets, svm, metrics\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "#let's look at digit. This is a set of data with some features that tell us things about handwriting samples for digits.\n",
    "print(digits.data)\n",
    "print(np.shape(digits.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "#The target shows the number the images are trying to show. There are 1797 different results, with an 8 x 8 grid of pixels\n",
    "print(digits.target)\n",
    "print(len(digits.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Here's a few examples to show the target of the training images.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It should be obvious that given the features of the pixel values, we should be able to group these images into the target number.\n",
    "np.shape(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "#We need to flatten the data into samples, features.\n",
    "n_samples = len(digits.data)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the data will be a 2d array with 64 features (the pixels) for each of 1797 sample images.\n",
    "data = digits.images.reshape(n_samples,-1)\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier. This is what is suggested in the tutorial for a simple vector classifier.\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "#Based on what I know about machine learning, gamma is a learning speed parameter for minimization. The higher it is, the faster the fit converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sklearn takes over from hear to fit these features in order to predict which digit they are. We divide into a teaching and target sample.\n",
    "classifier.fit(data[:n_samples//2][:],digits.target[:n_samples//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can use that fit to classify the expected target for the remaining handwriting samples.\n",
    "expected = digits.target[n_samples//2:]\n",
    "predicted = classifier.predict(data[n_samples//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finally, let's measure how well this predicter works.\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
